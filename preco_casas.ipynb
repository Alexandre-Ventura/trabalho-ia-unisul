{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de IA - Usando Machine Learning\n",
    "\n",
    "Sistemas de Informa√ß√£o - UNISUL\n",
    "\n",
    "- Alexandre Ventura\n",
    "- Mateus Wanderlinde\n",
    "- J√∫lia Staub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Price Prediction - Predi√ß√£o de pre√ßo de casas\n",
    "\n",
    "A previs√£o dos pre√ßos dos im√≥veis est√° se tornando cada vez mais importante e ben√©fica. Os pre√ßos dos im√≥veis s√£o um bom indicador tanto da condi√ß√£o geral do mercado quanto da sa√∫de econ√¥mica de um pa√≠s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca pandas para tratamento dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# Lendo os dados e criando um Dataframe, chamado \"dados\"\n",
    "dados = pd.read_csv('/home/alexandre-ventura/trabalho_ia/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           4600 non-null   object \n",
      " 1   price          4600 non-null   float64\n",
      " 2   bedrooms       4600 non-null   float64\n",
      " 3   bathrooms      4600 non-null   float64\n",
      " 4   sqft_living    4600 non-null   int64  \n",
      " 5   sqft_lot       4600 non-null   int64  \n",
      " 6   floors         4600 non-null   float64\n",
      " 7   waterfront     4600 non-null   int64  \n",
      " 8   view           4600 non-null   int64  \n",
      " 9   condition      4600 non-null   int64  \n",
      " 10  sqft_above     4600 non-null   int64  \n",
      " 11  sqft_basement  4600 non-null   int64  \n",
      " 12  yr_built       4600 non-null   int64  \n",
      " 13  yr_renovated   4600 non-null   int64  \n",
      " 14  street         4600 non-null   object \n",
      " 15  city           4600 non-null   object \n",
      " 16  statezip       4600 non-null   object \n",
      " 17  country        4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(5)\n",
      "memory usage: 647.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Visualizando as informa√ß√µes do nosso Dataframe\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto o dataframe usado, cont√©m as seguintes colunas: \n",
    "\n",
    "* **date:** Data da venda da casa.\n",
    "* **price:** Pre√ßo de venda da casa.\n",
    "* **bedrooms:** N√∫mero de quartos.\n",
    "* **bathrooms:** N√∫mero de banheiros.\n",
    "* **sqft_living:** √Årea interna da casa em p√©s quadrados.\n",
    "* **sqft_lot:** √Årea do terreno em p√©s quadrados.\n",
    "* **floors:** N√∫mero de andares na casa.\n",
    "* **waterfront:** Indicador se a casa tem vista para a √°gua.\n",
    "* **view:** Classifica√ß√£o da vista da casa.\n",
    "* **condition:** Classifica√ß√£o da condi√ß√£o da casa.\n",
    "* **sqft_above:** √Årea acima do solo em p√©s quadrados.\n",
    "* **sqft_basement:** √Årea do por√£o em p√©s quadrados.\n",
    "* **yr_built:** Ano de constru√ß√£o da casa.\n",
    "* **yr_renovated:** Ano de renova√ß√£o da casa.\n",
    "* **street:** Rua da casa.\n",
    "* **city:** Cidade onde fica a casa.\n",
    "* **statezip:** C√≥digo postal do estado.\n",
    "* **country:** Pa√≠s onde a casa est√°."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao todo s√£o 18 colunas, mas ser√° que √© necess√°rio usar todas para fazer a predi√ß√£o?\n",
    "\n",
    "Vamos analisar algumas colunas do dataframe que √© poss√≠vel desconsiderar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "USA    4600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pegando os todos os valores da coluna \"country\"\n",
    "dados['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levando em conta que todas as casas est√£o no EUA, podemos apagar essa coluna pois ela n√£o influenciara na nossa predi√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"Country\" do nosso Dataframe\n",
    "dados.drop(['country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tamb√©m apagar a coluna \"street\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"street\" do nosso Dataframe\n",
    "dados.drop(['street'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"statezip\" do nosso Dataframe\n",
    "dados.drop(['statezip'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E tamb√©m a coluna \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          4600 non-null   float64\n",
      " 1   bedrooms       4600 non-null   float64\n",
      " 2   bathrooms      4600 non-null   float64\n",
      " 3   sqft_living    4600 non-null   int64  \n",
      " 4   sqft_lot       4600 non-null   int64  \n",
      " 5   floors         4600 non-null   float64\n",
      " 6   waterfront     4600 non-null   int64  \n",
      " 7   view           4600 non-null   int64  \n",
      " 8   condition      4600 non-null   int64  \n",
      " 9   sqft_above     4600 non-null   int64  \n",
      " 10  sqft_basement  4600 non-null   int64  \n",
      " 11  yr_built       4600 non-null   int64  \n",
      " 12  yr_renovated   4600 non-null   int64  \n",
      " 13  city           4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Visualizando o dataframe atualizando.\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que foram excluidas ambas as colunas, vamos verificar se existe algum valor nulo em nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "city             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o temos valores nulos, o que √© bom e nos poupa trabalho. \n",
    "\n",
    "Mas vamos olhar com mais calma algumas colunas. Importante destacar que todo o dataset est√° com medidas em ingl√™s.\n",
    "√â interessante convertemos alguns valores para medidas internacionais, para melhor interpreta√ß√£o e visualiza√ß√£o dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a √°rea interna da casa, de p√©s quadrados, para metros quadrados. \n",
    "dados['area_interna'] = (dados['sqft_living'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer isso com todas as colunas que apresentam a medida \"p√©s quadrados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a √°rea do terreno, de p√©s quadrados, para metros quadrados.\n",
    "dados['area_terreno'] = (dados['sqft_lot'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a √°rea acima do solo, de p√©s quadrados, para metros quadrados.\n",
    "dados['area_acima_solo'] = (dados['sqft_above'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a √°rea do por√£o, de p√©s quadrados, para metros quadrados.\n",
    "dados['area_porao'] = (dados['sqft_basement'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que todas as medidas de √°rea foram transformadas para metros quadrados, vamos olhar a nova configura√ß√£o\n",
    "das colunas, e remover as colunas modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   sqft_living      4600 non-null   int64  \n",
      " 4   sqft_lot         4600 non-null   int64  \n",
      " 5   floors           4600 non-null   float64\n",
      " 6   waterfront       4600 non-null   int64  \n",
      " 7   view             4600 non-null   int64  \n",
      " 8   condition        4600 non-null   int64  \n",
      " 9   sqft_above       4600 non-null   int64  \n",
      " 10  sqft_basement    4600 non-null   int64  \n",
      " 11  yr_built         4600 non-null   int64  \n",
      " 12  yr_renovated     4600 non-null   int64  \n",
      " 13  city             4600 non-null   object \n",
      " 14  area_interna     4600 non-null   float64\n",
      " 15  area_terreno     4600 non-null   float64\n",
      " 16  area_acima_solo  4600 non-null   float64\n",
      " 17  area_porao       4600 non-null   float64\n",
      "dtypes: float64(8), int64(9), object(1)\n",
      "memory usage: 647.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as colunas que cont√©m a medida \"p√©s quadrados\"\n",
    "dados.drop(['sqft_living'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_lot'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_above'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_basement'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   floors           4600 non-null   float64\n",
      " 4   waterfront       4600 non-null   int64  \n",
      " 5   view             4600 non-null   int64  \n",
      " 6   condition        4600 non-null   int64  \n",
      " 7   yr_built         4600 non-null   int64  \n",
      " 8   yr_renovated     4600 non-null   int64  \n",
      " 9   city             4600 non-null   object \n",
      " 10  area_interna     4600 non-null   float64\n",
      " 11  area_terreno     4600 non-null   float64\n",
      " 12  area_acima_solo  4600 non-null   float64\n",
      " 13  area_porao       4600 non-null   float64\n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse √© o novo conjunto de colunas que temos em nosso dataframe:\n",
    "\n",
    "* **price:** Pre√ßo de venda da casa.\n",
    "* **bedrooms:** N√∫mero de quartos.\n",
    "* **bathrooms:** N√∫mero de banheiros.\n",
    "* **floors:** N√∫mero de andares na casa.\n",
    "* **waterfront:** Indicador se a casa tem vista para a √°gua.\n",
    "* **view:** Classifica√ß√£o da vista da casa.\n",
    "* **condition:** Classifica√ß√£o da condi√ß√£o da casa.\n",
    "* **yr_built:** Ano de constru√ß√£o da casa.\n",
    "* **yr_renovated:** Ano de renova√ß√£o da casa.\n",
    "* **city:** Cidade onde fica a casa.\n",
    "* **statezip:** C√≥digo postal do estado.\n",
    "* **area_interna:** √Årea interna da casa em metros quadrados.\n",
    "* **area_terreno:** √Årea do terreno em metros quadrados.\n",
    "* **area_acima_solo:** √Årea acima do solo em metros quadrados.\n",
    "* **area_porao:** √Årea do por√£o em metros quadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se olharmos com aten√ß√£o para nosso dataset ainda vamos encontrar algumas coisas que aparentemente n√£o faz muito sentido. Por exemplo nas colunas \"bathrooms\" e \"floors\", como uma casa pode ter 1.75 banheiros? Ou 2.5 andares?\n",
    "\n",
    "Por isso decidimos arredondar para n√∫meros inteiros, antes de come√ßarmos nossa analise explorat√≥ria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms\n",
       "2.50    1189\n",
       "1.00     743\n",
       "1.75     629\n",
       "2.00     427\n",
       "2.25     419\n",
       "1.50     291\n",
       "2.75     276\n",
       "3.00     167\n",
       "3.50     162\n",
       "3.25     136\n",
       "3.75      37\n",
       "4.50      29\n",
       "4.00      23\n",
       "4.25      23\n",
       "0.75      17\n",
       "4.75       7\n",
       "5.00       6\n",
       "5.25       4\n",
       "5.50       4\n",
       "1.25       3\n",
       "0.00       2\n",
       "6.25       2\n",
       "5.75       1\n",
       "8.00       1\n",
       "6.50       1\n",
       "6.75       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos banheiros cada casa possui.\n",
    "dados['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredondando a quantidade de banheiros em n√∫meros inteiros.\n",
    "dados['bathrooms'] = dados['bathrooms'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms\n",
       "2.0    2955\n",
       "1.0     763\n",
       "3.0     579\n",
       "4.0     274\n",
       "5.0      17\n",
       "6.0       8\n",
       "0.0       2\n",
       "8.0       1\n",
       "7.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos banheiros cada casa possui, agora em n√∫meros inteiros. \n",
    "dados['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° atualizamos os valores de \"bathrooms\", vamos atualizar os valores de \"floors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredondando a quantidade de andares em n√∫meros inteiros.\n",
    "dados['floors'] = dados['floors'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "floors\n",
       "2.0    2296\n",
       "1.0    2174\n",
       "3.0     128\n",
       "4.0       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos andares cada casa possui, agora em n√∫meros inteiros. \n",
    "dados['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda podemos melhorar alguns dados, por exemplo, ao inv√©s do ano de constru√ß√£o, mostrar quantos anos cada casa possui. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando uma biblioteca que nos ajudar√° a trabalhar com datas\n",
    "from datetime import datetime\n",
    "\n",
    "dados[\"idade_casa\"] = datetime.today().year - dados[\"yr_built\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(['yr_built'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   floors           4600 non-null   float64\n",
      " 4   waterfront       4600 non-null   int64  \n",
      " 5   view             4600 non-null   int64  \n",
      " 6   condition        4600 non-null   int64  \n",
      " 7   yr_renovated     4600 non-null   int64  \n",
      " 8   city             4600 non-null   object \n",
      " 9   area_interna     4600 non-null   float64\n",
      " 10  area_terreno     4600 non-null   float64\n",
      " 11  area_acima_solo  4600 non-null   float64\n",
      " 12  area_porao       4600 non-null   float64\n",
      " 13  idade_casa       4600 non-null   int64  \n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos partir para a escolha do modelo de treinamento de m√°quina, e avalia√ß√£o do mesmo modelo.\n",
    "Mas antes vamos preparar ainda mais os dados para o treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas features\n",
    "\n",
    "# importando a bibiloteca numpy para manipula√ß√£o matem√°ticas. \n",
    "import numpy as np\n",
    "\n",
    "# Criando uma nova coluna\n",
    "dados['idade_apos_renovacao'] = np.where(dados['yr_renovated'] > 0, \n",
    "                                         datetime.today().year - dados['yr_renovated'], \n",
    "                                         dados['idade_casa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo coluna\n",
    "dados.drop(['yr_renovated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â interessante que removamos os Outliers. Outliers s√£o valores muito diferentes da maioria dos dados, como se fossem \"fora da curva\". Eles podem ser muito altos ou muito baixos em rela√ß√£o ao restante do conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui iremos remover outliers (valores muito altos) na coluna price, mantendo apenas os 97% das casas mais baratas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casas removidas por outliers: 138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # Remover outliers nos pre√ßos (acima do percentil 97%)\\nlimite_superior = np.percentile(dados['price'], 97)\\ndados = dados[dados['price'] < limite_superior] \""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir um limite superior baseado no percentil 97% dos pre√ßos das casas\n",
    "limite_superior = np.percentile(dados['price'], 97)\n",
    "\n",
    "# Filtrar os dados, removendo as casas que possuem pre√ßos acima do limite\n",
    "dados_filtrados = dados[dados['price'] < limite_superior]\n",
    "\n",
    "# Exibir quantas casas foram removidas\n",
    "print(f\"Casas removidas por outliers: {dados.shape[0] - dados_filtrados.shape[0]}\")\n",
    "dados = dados[dados['price'] < limite_superior]\n",
    "\n",
    "\"\"\" # Remover outliers nos pre√ßos (acima do percentil 97%)\n",
    "limite_superior = np.percentile(dados['price'], 97)\n",
    "dados = dados[dados['price'] < limite_superior] \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o LabelEncoder, para tratar com nossas strings. \n",
    "\n",
    "Esse c√≥digo transforma a coluna categ√≥rica 'city' em n√∫meros, permitindo que o modelo de Machine Learning a utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Converter colunas categ√≥ricas\n",
    "label_encoder = LabelEncoder()\n",
    "dados['city'] = label_encoder.fit_transform(dados['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "X = dados.drop(['price'], axis=1)\n",
    "y = dados['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo separados as features (colunas que ser√£o usadas no treino), e o target (coluna de teste) vamos dividir os dados. Esse c√≥digo divide os dados em treino e teste, permitindo que o modelo aprenda com uma parte dos dados e seja avaliado com outra parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar o StandardScaler(), que √© uma classe de pr√©-processamento de dados do scikit-learn. Essa classe ajuda a normalizar a escala dos dados, o que √© crucial para muitos algoritmos de aprendizado de m√°quina que s√£o sens√≠veis √† varia√ß√£o nas escalas das caracter√≠sticas (features) dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando voc√™ aplica a StandardScaler() a um conjunto de dados, ela realiza as seguintes etapas para cada caracter√≠stica:\n",
    "\n",
    "- Calcula a m√©dia de cada caracter√≠stica.\n",
    "- Calcula o desvio padr√£o de cada caracter√≠stica, medindo qu√£o dispersos est√£o os valores em rela√ß√£o √† m√©dia.\n",
    "- Normaliza os valores subtraindo a m√©dia e dividindo pelo desvio padr√£o para cada valor de caracter√≠stica, com a f√≥rmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este processo de normaliza√ß√£o ajusta os dados de tal forma que a m√©dia das caracter√≠sticas transformadas √© zero e o desvio padr√£o √© um. Isso √© importante porque muitos algoritmos de machine learning performam melhor quando as caracter√≠sticas est√£o na mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este trabalho vamos usar dois modelos que lidam bem com problemas de regress√£o, como previs√£o de vendas.\n",
    "\n",
    "XGBoost e LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Treinar o modelo XGBoost\n",
    "modelo_xgb = XGBRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "modelo_xgb.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = modelo_xgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost:** Imagine que voc√™ quer adivinhar o pre√ßo de uma casa. O XGBoost funciona como um time de especialistas que fazem previs√µes, aprendendo com os erros uns dos outros. Ele come√ßa com uma previs√£o simples e, a cada rodada, melhora corrigindo os erros anteriores. Esse m√©todo, chamado boosting, faz com que o modelo fique mais preciso a cada passo. √â √≥timo para encontrar padr√µes escondidos, mas pode ser um pouco mais lento em grandes volumes de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1195\n",
      "[LightGBM] [Info] Number of data points in the train set: 3569, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 502331.273114\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Treinar o modelo LightGBM\n",
    "modelo_lgb = LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "modelo_lgb.fit(X_train_scaled, y_train)\n",
    "y_pred_lgb = modelo_lgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM:** O LightGBM faz algo parecido, mas de forma mais r√°pida e eficiente. Em vez de crescer todas as √°rvores da mesma forma, ele foca primeiro nas partes mais importantes, acelerando o aprendizado. Isso faz com que funcione muito bem em grandes conjuntos de dados, sem precisar de tanto tempo ou mem√≥ria do computador. Por√©m, por ser muito agressivo na busca por padr√µes, pode ser um pouco mais sens√≠vel a erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalia√ß√£o do Modelo: MAE e RMSE\n",
    "\n",
    "#### MAE (Mean Absolute Error) - Erro M√©dio Absoluto\n",
    "O **MAE** mede a m√©dia dos erros absolutos entre os valores reais e os previstos. Ele indica, em m√©dia, o quanto nossas previs√µes est√£o erradas.  \n",
    "- Quanto **menor o MAE**, melhor o modelo.  \n",
    "- Representa o erro m√©dio em unidades monet√°rias.  \n",
    "\n",
    "\n",
    "\n",
    "#### RMSE (Root Mean Squared Error) - Raiz do Erro Quadr√°tico M√©dio\n",
    "O **RMSE** calcula o erro m√©dio, mas dando mais peso para erros grandes. Ele √© mais sens√≠vel a outliers do que o MAE.  \n",
    "- Quanto **menor o RMSE**, melhor o modelo.  \n",
    "- Penaliza erros grandes mais do que o MAE.  \n",
    "\n",
    "\n",
    "\n",
    "### Diferen√ßa entre MAE e RMSE\n",
    "|  | **MAE** | **RMSE** |\n",
    "|---|---|---|\n",
    "| **Interpreta√ß√£o** | Erro m√©dio absoluto | Penaliza erros grandes |\n",
    "| **Sensibilidade a outliers** | Baixa | Alta |\n",
    "| **Uso** | Se erros grandes n√£o forem t√£o cr√≠ticos | Se erros grandes devem ser evitados |\n",
    "\n",
    "Para escolher entre MAE e RMSE, depende do objetivo do modelo. Se queremos um erro m√©dio mais interpret√°vel, usamos MAE. Se queremos um modelo que evite grandes desvios, usamos RMSE. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE XGBoost: 103800.24\n",
      "RMSE XGBoost: 164945.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Avalia√ß√£o do XGBoost\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb) ** 0.5\n",
    "print(f'MAE XGBoost: {mae_xgb:.2f}')\n",
    "print(f'RMSE XGBoost: {rmse_xgb:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LightGBM: 105277.82\n",
      "RMSE LightGBM: 164486.64\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o do LightGBM\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = mean_squared_error(y_test, y_pred_lgb) ** 0.5\n",
    "print(f'MAE LightGBM: {mae_lgb:.2f}')\n",
    "print(f'RMSE LightGBM: {rmse_lgb:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que MAE e RMSE s√£o importantes?\n",
    "\n",
    "Avaliar um modelo de Machine Learning √© essencial para garantir que suas previs√µes sejam precisas e √∫teis. **MAE e RMSE nos ajudam a entender o qu√£o pr√≥ximos os valores previstos est√£o dos valores reais.**\n",
    "\n",
    "### Principais Motivos para Calcular MAE e RMSE  \n",
    "\n",
    "- **Medi√ß√£o da Qualidade do Modelo:**  \n",
    "Essas m√©tricas indicam o **erro m√©dio das previs√µes**, permitindo saber se o modelo est√° funcionando bem ou precisa de ajustes.  \n",
    "\n",
    "- **Compara√ß√£o entre Modelos:**  \n",
    "Se testamos diferentes algoritmos (XGBoost, LightGBM, etc.), podemos comparar os erros e escolher o melhor.  \n",
    "\n",
    "- **Ajuste de Hiperpar√¢metros:**  \n",
    "Usamos essas m√©tricas para verificar **se as altera√ß√µes no modelo melhoram ou pioram seu desempenho**.  \n",
    "\n",
    "**Evitar Problemas como Overfitting e Underfitting**  \n",
    "- Se o erro for **muito alto**, o modelo pode n√£o ter aprendido o suficiente (**underfitting**).  \n",
    "- Se o erro no treino for muito menor do que no teste, o modelo pode estar **decorando os dados** (**overfitting**).  \n",
    "\n",
    "**Tomada de Decis√£o**  \n",
    "Se o erro m√©dio √© de **$100.000**, sabemos que o modelo pode estar **subestimando ou superestimando os pre√ßos** e podemos considerar ajustes.  \n",
    "\n",
    "**Conclus√£o:** MAE e RMSE s√£o essenciais para avaliar e aprimorar modelos de Machine Learning, garantindo que suas previs√µes sejam mais confi√°veis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre√ßo m√©dio das casas: $499,859.71\n"
     ]
    }
   ],
   "source": [
    "preco_medio = dados[\"price\"].mean()\n",
    "print(f'Pre√ßo m√©dio das casas: ${preco_medio:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o algoritmo prever o pre√ßo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos fazer com que o algoritmo preva o pre√ßo das casas, e faremos isso com os dois modelos diferentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre√ßo previsto para o novo im√≥vel: $960,084.12\n"
     ]
    }
   ],
   "source": [
    "# Criando um dicion√°rio com os dados de um novo im√≥vel\n",
    "novo_imovel = {\n",
    "    'city': 'Seattle', \n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2,\n",
    "    'floors': 1,\n",
    "    'waterfront': 0,\n",
    "    'view': 2,\n",
    "    'condition': 4,\n",
    "    'idade_casa': 20,\n",
    "    'area_interna': 150,\n",
    "    'area_terreno': 300,\n",
    "    'area_acima_solo': 120,\n",
    "    'area_porao': 30,\n",
    "    'idade_apos_renovacao': 25\n",
    "}\n",
    "\n",
    "# Convertendo a cidade para o valor num√©rico usando LabelEncoder\n",
    "novo_imovel['city'] = label_encoder.transform([novo_imovel['city']])[0]\n",
    "\n",
    "# Convertendo para um DataFrame\n",
    "novo_imovel_df = pd.DataFrame([novo_imovel])\n",
    "\n",
    "# Fazer a previs√£o com o modelo treinado\n",
    "previsao = modelo_xgb.predict(novo_imovel_df)\n",
    "\n",
    "print(f'Pre√ßo previsto para o novo im√≥vel: ${previsao[0]:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo XGboost, preveu que uma casa, com aqueles dados que inserimos vale $960,084.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre√ßo previsto para o novo im√≥vel: $957,879.85\n"
     ]
    }
   ],
   "source": [
    "# Criando um dicion√°rio com os dados de um novo im√≥vel\n",
    "novo_imovel = {\n",
    "    'city': 'Seattle', \n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2,\n",
    "    'floors': 1,\n",
    "    'waterfront': 0,\n",
    "    'view': 2,\n",
    "    'condition': 4,\n",
    "    'idade_casa': 20,\n",
    "    'area_interna': 150,\n",
    "    'area_terreno': 300,\n",
    "    'area_acima_solo': 120,\n",
    "    'area_porao': 30,\n",
    "    'idade_apos_renovacao': 25\n",
    "}\n",
    "\n",
    "# Convertendo a cidade para o valor num√©rico usando LabelEncoder\n",
    "novo_imovel['city'] = label_encoder.transform([novo_imovel['city']])[0]\n",
    "\n",
    "# Convertendo para um DataFrame\n",
    "novo_imovel_df = pd.DataFrame([novo_imovel])\n",
    "\n",
    "# Fazer a previs√£o com o modelo treinado\n",
    "previsao = modelo_lgb.predict(novo_imovel_df)\n",
    "\n",
    "print(f'Pre√ßo previsto para o novo im√≥vel: ${previsao[0]:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os mesmos dados o modelo LightGBM previu que a casa √© avaliada em $957,879.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalia√ß√£o dos Modelos\n",
    "\n",
    "### Resultados:\n",
    "\n",
    "#### XGBoost:\n",
    "- **MAE:** $103,800 ‚Üí 20,8% do pre√ßo m√©dio  \n",
    "- **RMSE:** $164,945 ‚Üí 32,9% do pre√ßo m√©dio  \n",
    "\n",
    "#### LightGBM:\n",
    "- **MAE:** $105,277 ‚Üí 21,0% do pre√ßo m√©dio  \n",
    "- **RMSE:** $164,486 ‚Üí 32,9% do pre√ßo m√©dio  \n",
    "\n",
    "\n",
    "\n",
    "### O que isso significa?\n",
    "- O **erro m√©dio absoluto (MAE)** indica que, em m√©dia, o modelo erra o pre√ßo da casa em cerca de **$103K a $105K**.  \n",
    "- O **RMSE** sugere que os erros maiores (**outliers**) podem estar impactando o modelo, pois o valor est√° acima de **30% do pre√ßo m√©dio**.  \n",
    "- Como o erro representa cerca de **20-21% do pre√ßo m√©dio**, o modelo j√° tem um desempenho razo√°vel, mas pode melhorar.  \n",
    "\n",
    "\n",
    "\n",
    "### Poss√≠veis Melhorias:\n",
    "1Ô∏è**Feature Engineering:** Criar novas vari√°veis, como **densidade populacional da cidade** ou **pre√ßo m√©dio por metro quadrado**.  \n",
    "2Ô∏è **Tratar Outliers:** Como o **RMSE √© bem maior que o MAE**, pode haver **outliers influenciando o modelo**. Podemos testar a remo√ß√£o de valores extremos no pre√ßo.  \n",
    "3Ô∏è **Ajuste de Hiperpar√¢metros:** Testar **GridSearchCV** ou **Optuna** para encontrar os melhores par√¢metros para XGBoost e LightGBM.  \n",
    "4Ô∏è **Modelos Ensemble:** Criar um modelo que **combine XGBoost e LightGBM** para aproveitar o melhor de ambos.  \n",
    "\n",
    "**Conclus√£o:** O modelo j√° apresenta um bom desempenho, mas ainda h√° espa√ßo para melhorias!  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
