{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de IA - Usando Machine Learning\n",
    "\n",
    "Sistemas de Informação - UNISUL\n",
    "\n",
    "- Alexandre Ventura\n",
    "- Mateus Wanderlinde\n",
    "- Júlia Staub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Price Prediction - Predição de preço de casas\n",
    "\n",
    "A previsão dos preços dos imóveis está se tornando cada vez mais importante e benéfica. Os preços dos imóveis são um bom indicador tanto da condição geral do mercado quanto da saúde econômica de um país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca pandas para tratamento dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# Lendo os dados e criando um Dataframe, chamado \"dados\"\n",
    "dados = pd.read_csv('/home/alexandre-ventura/trabalho_ia/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           4600 non-null   object \n",
      " 1   price          4600 non-null   float64\n",
      " 2   bedrooms       4600 non-null   float64\n",
      " 3   bathrooms      4600 non-null   float64\n",
      " 4   sqft_living    4600 non-null   int64  \n",
      " 5   sqft_lot       4600 non-null   int64  \n",
      " 6   floors         4600 non-null   float64\n",
      " 7   waterfront     4600 non-null   int64  \n",
      " 8   view           4600 non-null   int64  \n",
      " 9   condition      4600 non-null   int64  \n",
      " 10  sqft_above     4600 non-null   int64  \n",
      " 11  sqft_basement  4600 non-null   int64  \n",
      " 12  yr_built       4600 non-null   int64  \n",
      " 13  yr_renovated   4600 non-null   int64  \n",
      " 14  street         4600 non-null   object \n",
      " 15  city           4600 non-null   object \n",
      " 16  statezip       4600 non-null   object \n",
      " 17  country        4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(5)\n",
      "memory usage: 647.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Visualizando as informações do nosso Dataframe\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto o dataframe usado, contém as seguintes colunas: \n",
    "\n",
    "* **date:** Data da venda da casa.\n",
    "* **price:** Preço de venda da casa.\n",
    "* **bedrooms:** Número de quartos.\n",
    "* **bathrooms:** Número de banheiros.\n",
    "* **sqft_living:** Área interna da casa em pés quadrados.\n",
    "* **sqft_lot:** Área do terreno em pés quadrados.\n",
    "* **floors:** Número de andares na casa.\n",
    "* **waterfront:** Indicador se a casa tem vista para a água.\n",
    "* **view:** Classificação da vista da casa.\n",
    "* **condition:** Classificação da condição da casa.\n",
    "* **sqft_above:** Área acima do solo em pés quadrados.\n",
    "* **sqft_basement:** Área do porão em pés quadrados.\n",
    "* **yr_built:** Ano de construção da casa.\n",
    "* **yr_renovated:** Ano de renovação da casa.\n",
    "* **street:** Rua da casa.\n",
    "* **city:** Cidade onde fica a casa.\n",
    "* **statezip:** Código postal do estado.\n",
    "* **country:** País onde a casa está."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao todo são 18 colunas, mas será que é necessário usar todas para fazer a predição?\n",
    "\n",
    "Vamos analisar algumas colunas do dataframe que é possível desconsiderar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "USA    4600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pegando os todos os valores da coluna \"country\"\n",
    "dados['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levando em conta que todas as casas estão no EUA, podemos apagar essa coluna pois ela não influenciara na nossa predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"Country\" do nosso Dataframe\n",
    "dados.drop(['country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também apagar a coluna \"street\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"street\" do nosso Dataframe\n",
    "dados.drop(['street'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna \"statezip\" do nosso Dataframe\n",
    "dados.drop(['statezip'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E também a coluna \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          4600 non-null   float64\n",
      " 1   bedrooms       4600 non-null   float64\n",
      " 2   bathrooms      4600 non-null   float64\n",
      " 3   sqft_living    4600 non-null   int64  \n",
      " 4   sqft_lot       4600 non-null   int64  \n",
      " 5   floors         4600 non-null   float64\n",
      " 6   waterfront     4600 non-null   int64  \n",
      " 7   view           4600 non-null   int64  \n",
      " 8   condition      4600 non-null   int64  \n",
      " 9   sqft_above     4600 non-null   int64  \n",
      " 10  sqft_basement  4600 non-null   int64  \n",
      " 11  yr_built       4600 non-null   int64  \n",
      " 12  yr_renovated   4600 non-null   int64  \n",
      " 13  city           4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Visualizando o dataframe atualizando.\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que foram excluidas ambas as colunas, vamos verificar se existe algum valor nulo em nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "city             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não temos valores nulos, o que é bom e nos poupa trabalho. \n",
    "\n",
    "Mas vamos olhar com mais calma algumas colunas. Importante destacar que todo o dataset está com medidas em inglês.\n",
    "É interessante convertemos alguns valores para medidas internacionais, para melhor interpretação e visualização dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a área interna da casa, de pés quadrados, para metros quadrados. \n",
    "dados['area_interna'] = (dados['sqft_living'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer isso com todas as colunas que apresentam a medida \"pés quadrados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a área do terreno, de pés quadrados, para metros quadrados.\n",
    "dados['area_terreno'] = (dados['sqft_lot'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a área acima do solo, de pés quadrados, para metros quadrados.\n",
    "dados['area_acima_solo'] = (dados['sqft_above'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a área do porão, de pés quadrados, para metros quadrados.\n",
    "dados['area_porao'] = (dados['sqft_basement'] * 0.0929).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que todas as medidas de área foram transformadas para metros quadrados, vamos olhar a nova configuração\n",
    "das colunas, e remover as colunas modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   sqft_living      4600 non-null   int64  \n",
      " 4   sqft_lot         4600 non-null   int64  \n",
      " 5   floors           4600 non-null   float64\n",
      " 6   waterfront       4600 non-null   int64  \n",
      " 7   view             4600 non-null   int64  \n",
      " 8   condition        4600 non-null   int64  \n",
      " 9   sqft_above       4600 non-null   int64  \n",
      " 10  sqft_basement    4600 non-null   int64  \n",
      " 11  yr_built         4600 non-null   int64  \n",
      " 12  yr_renovated     4600 non-null   int64  \n",
      " 13  city             4600 non-null   object \n",
      " 14  area_interna     4600 non-null   float64\n",
      " 15  area_terreno     4600 non-null   float64\n",
      " 16  area_acima_solo  4600 non-null   float64\n",
      " 17  area_porao       4600 non-null   float64\n",
      "dtypes: float64(8), int64(9), object(1)\n",
      "memory usage: 647.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as colunas que contém a medida \"pés quadrados\"\n",
    "dados.drop(['sqft_living'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_lot'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_above'], axis=1, inplace=True)\n",
    "dados.drop(['sqft_basement'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   floors           4600 non-null   float64\n",
      " 4   waterfront       4600 non-null   int64  \n",
      " 5   view             4600 non-null   int64  \n",
      " 6   condition        4600 non-null   int64  \n",
      " 7   yr_built         4600 non-null   int64  \n",
      " 8   yr_renovated     4600 non-null   int64  \n",
      " 9   city             4600 non-null   object \n",
      " 10  area_interna     4600 non-null   float64\n",
      " 11  area_terreno     4600 non-null   float64\n",
      " 12  area_acima_solo  4600 non-null   float64\n",
      " 13  area_porao       4600 non-null   float64\n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é o novo conjunto de colunas que temos em nosso dataframe:\n",
    "\n",
    "* **price:** Preço de venda da casa.\n",
    "* **bedrooms:** Número de quartos.\n",
    "* **bathrooms:** Número de banheiros.\n",
    "* **floors:** Número de andares na casa.\n",
    "* **waterfront:** Indicador se a casa tem vista para a água.\n",
    "* **view:** Classificação da vista da casa.\n",
    "* **condition:** Classificação da condição da casa.\n",
    "* **yr_built:** Ano de construção da casa.\n",
    "* **yr_renovated:** Ano de renovação da casa.\n",
    "* **city:** Cidade onde fica a casa.\n",
    "* **statezip:** Código postal do estado.\n",
    "* **area_interna:** Área interna da casa em metros quadrados.\n",
    "* **area_terreno:** Área do terreno em metros quadrados.\n",
    "* **area_acima_solo:** Área acima do solo em metros quadrados.\n",
    "* **area_porao:** Área do porão em metros quadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se olharmos com atenção para nosso dataset ainda vamos encontrar algumas coisas que aparentemente não faz muito sentido. Por exemplo nas colunas \"bathrooms\" e \"floors\", como uma casa pode ter 1.75 banheiros? Ou 2.5 andares?\n",
    "\n",
    "Por isso decidimos arredondar para números inteiros, antes de começarmos nossa analise exploratória. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms\n",
       "2.50    1189\n",
       "1.00     743\n",
       "1.75     629\n",
       "2.00     427\n",
       "2.25     419\n",
       "1.50     291\n",
       "2.75     276\n",
       "3.00     167\n",
       "3.50     162\n",
       "3.25     136\n",
       "3.75      37\n",
       "4.50      29\n",
       "4.00      23\n",
       "4.25      23\n",
       "0.75      17\n",
       "4.75       7\n",
       "5.00       6\n",
       "5.25       4\n",
       "5.50       4\n",
       "1.25       3\n",
       "0.00       2\n",
       "6.25       2\n",
       "5.75       1\n",
       "8.00       1\n",
       "6.50       1\n",
       "6.75       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos banheiros cada casa possui.\n",
    "dados['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredondando a quantidade de banheiros em números inteiros.\n",
    "dados['bathrooms'] = dados['bathrooms'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms\n",
       "2.0    2955\n",
       "1.0     763\n",
       "3.0     579\n",
       "4.0     274\n",
       "5.0      17\n",
       "6.0       8\n",
       "0.0       2\n",
       "8.0       1\n",
       "7.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos banheiros cada casa possui, agora em números inteiros. \n",
    "dados['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já atualizamos os valores de \"bathrooms\", vamos atualizar os valores de \"floors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredondando a quantidade de andares em números inteiros.\n",
    "dados['floors'] = dados['floors'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "floors\n",
       "2.0    2296\n",
       "1.0    2174\n",
       "3.0     128\n",
       "4.0       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando quantos andares cada casa possui, agora em números inteiros. \n",
    "dados['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda podemos melhorar alguns dados, por exemplo, ao invés do ano de construção, mostrar quantos anos cada casa possui. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando uma biblioteca que nos ajudará a trabalhar com datas\n",
    "from datetime import datetime\n",
    "\n",
    "dados[\"idade_casa\"] = datetime.today().year - dados[\"yr_built\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(['yr_built'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   price            4600 non-null   float64\n",
      " 1   bedrooms         4600 non-null   float64\n",
      " 2   bathrooms        4600 non-null   float64\n",
      " 3   floors           4600 non-null   float64\n",
      " 4   waterfront       4600 non-null   int64  \n",
      " 5   view             4600 non-null   int64  \n",
      " 6   condition        4600 non-null   int64  \n",
      " 7   yr_renovated     4600 non-null   int64  \n",
      " 8   city             4600 non-null   object \n",
      " 9   area_interna     4600 non-null   float64\n",
      " 10  area_terreno     4600 non-null   float64\n",
      " 11  area_acima_solo  4600 non-null   float64\n",
      " 12  area_porao       4600 non-null   float64\n",
      " 13  idade_casa       4600 non-null   int64  \n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 503.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos partir para a escolha do modelo de treinamento de máquina, e avaliação do mesmo modelo.\n",
    "Mas antes vamos preparar ainda mais os dados para o treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas features\n",
    "\n",
    "# importando a bibiloteca numpy para manipulação matemáticas. \n",
    "import numpy as np\n",
    "\n",
    "# Criando uma nova coluna\n",
    "dados['idade_apos_renovacao'] = np.where(dados['yr_renovated'] > 0, \n",
    "                                         datetime.today().year - dados['yr_renovated'], \n",
    "                                         dados['idade_casa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo coluna\n",
    "dados.drop(['yr_renovated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante que removamos os Outliers. Outliers são valores muito diferentes da maioria dos dados, como se fossem \"fora da curva\". Eles podem ser muito altos ou muito baixos em relação ao restante do conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui iremos remover outliers (valores muito altos) na coluna price, mantendo apenas os 97% das casas mais baratas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casas removidas por outliers: 138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # Remover outliers nos preços (acima do percentil 97%)\\nlimite_superior = np.percentile(dados['price'], 97)\\ndados = dados[dados['price'] < limite_superior] \""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir um limite superior baseado no percentil 97% dos preços das casas\n",
    "limite_superior = np.percentile(dados['price'], 97)\n",
    "\n",
    "# Filtrar os dados, removendo as casas que possuem preços acima do limite\n",
    "dados_filtrados = dados[dados['price'] < limite_superior]\n",
    "\n",
    "# Exibir quantas casas foram removidas\n",
    "print(f\"Casas removidas por outliers: {dados.shape[0] - dados_filtrados.shape[0]}\")\n",
    "dados = dados[dados['price'] < limite_superior]\n",
    "\n",
    "\"\"\" # Remover outliers nos preços (acima do percentil 97%)\n",
    "limite_superior = np.percentile(dados['price'], 97)\n",
    "dados = dados[dados['price'] < limite_superior] \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o LabelEncoder, para tratar com nossas strings. \n",
    "\n",
    "Esse código transforma a coluna categórica 'city' em números, permitindo que o modelo de Machine Learning a utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Converter colunas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "dados['city'] = label_encoder.fit_transform(dados['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "X = dados.drop(['price'], axis=1)\n",
    "y = dados['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo separados as features (colunas que serão usadas no treino), e o target (coluna de teste) vamos dividir os dados. Esse código divide os dados em treino e teste, permitindo que o modelo aprenda com uma parte dos dados e seja avaliado com outra parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar o StandardScaler(), que é uma classe de pré-processamento de dados do scikit-learn. Essa classe ajuda a normalizar a escala dos dados, o que é crucial para muitos algoritmos de aprendizado de máquina que são sensíveis à variação nas escalas das características (features) dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando você aplica a StandardScaler() a um conjunto de dados, ela realiza as seguintes etapas para cada característica:\n",
    "\n",
    "- Calcula a média de cada característica.\n",
    "- Calcula o desvio padrão de cada característica, medindo quão dispersos estão os valores em relação à média.\n",
    "- Normaliza os valores subtraindo a média e dividindo pelo desvio padrão para cada valor de característica, com a fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este processo de normalização ajusta os dados de tal forma que a média das características transformadas é zero e o desvio padrão é um. Isso é importante porque muitos algoritmos de machine learning performam melhor quando as características estão na mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este trabalho vamos usar dois modelos que lidam bem com problemas de regressão, como previsão de vendas.\n",
    "\n",
    "XGBoost e LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Treinar o modelo XGBoost\n",
    "modelo_xgb = XGBRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "modelo_xgb.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = modelo_xgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost:** Imagine que você quer adivinhar o preço de uma casa. O XGBoost funciona como um time de especialistas que fazem previsões, aprendendo com os erros uns dos outros. Ele começa com uma previsão simples e, a cada rodada, melhora corrigindo os erros anteriores. Esse método, chamado boosting, faz com que o modelo fique mais preciso a cada passo. É ótimo para encontrar padrões escondidos, mas pode ser um pouco mais lento em grandes volumes de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1195\n",
      "[LightGBM] [Info] Number of data points in the train set: 3569, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 502331.273114\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Treinar o modelo LightGBM\n",
    "modelo_lgb = LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "modelo_lgb.fit(X_train_scaled, y_train)\n",
    "y_pred_lgb = modelo_lgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM:** O LightGBM faz algo parecido, mas de forma mais rápida e eficiente. Em vez de crescer todas as árvores da mesma forma, ele foca primeiro nas partes mais importantes, acelerando o aprendizado. Isso faz com que funcione muito bem em grandes conjuntos de dados, sem precisar de tanto tempo ou memória do computador. Porém, por ser muito agressivo na busca por padrões, pode ser um pouco mais sensível a erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo: MAE e RMSE\n",
    "\n",
    "#### MAE (Mean Absolute Error) - Erro Médio Absoluto\n",
    "O **MAE** mede a média dos erros absolutos entre os valores reais e os previstos. Ele indica, em média, o quanto nossas previsões estão erradas.  \n",
    "- Quanto **menor o MAE**, melhor o modelo.  \n",
    "- Representa o erro médio em unidades monetárias.  \n",
    "\n",
    "\n",
    "\n",
    "#### RMSE (Root Mean Squared Error) - Raiz do Erro Quadrático Médio\n",
    "O **RMSE** calcula o erro médio, mas dando mais peso para erros grandes. Ele é mais sensível a outliers do que o MAE.  \n",
    "- Quanto **menor o RMSE**, melhor o modelo.  \n",
    "- Penaliza erros grandes mais do que o MAE.  \n",
    "\n",
    "\n",
    "\n",
    "### Diferença entre MAE e RMSE\n",
    "|  | **MAE** | **RMSE** |\n",
    "|---|---|---|\n",
    "| **Interpretação** | Erro médio absoluto | Penaliza erros grandes |\n",
    "| **Sensibilidade a outliers** | Baixa | Alta |\n",
    "| **Uso** | Se erros grandes não forem tão críticos | Se erros grandes devem ser evitados |\n",
    "\n",
    "Para escolher entre MAE e RMSE, depende do objetivo do modelo. Se queremos um erro médio mais interpretável, usamos MAE. Se queremos um modelo que evite grandes desvios, usamos RMSE. 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE XGBoost: 103800.24\n",
      "RMSE XGBoost: 164945.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Avaliação do XGBoost\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb) ** 0.5\n",
    "print(f'MAE XGBoost: {mae_xgb:.2f}')\n",
    "print(f'RMSE XGBoost: {rmse_xgb:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LightGBM: 105277.82\n",
      "RMSE LightGBM: 164486.64\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do LightGBM\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = mean_squared_error(y_test, y_pred_lgb) ** 0.5\n",
    "print(f'MAE LightGBM: {mae_lgb:.2f}')\n",
    "print(f'RMSE LightGBM: {rmse_lgb:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que MAE e RMSE são importantes?\n",
    "\n",
    "Avaliar um modelo de Machine Learning é essencial para garantir que suas previsões sejam precisas e úteis. **MAE e RMSE nos ajudam a entender o quão próximos os valores previstos estão dos valores reais.**\n",
    "\n",
    "### Principais Motivos para Calcular MAE e RMSE  \n",
    "\n",
    "- **Medição da Qualidade do Modelo:**  \n",
    "Essas métricas indicam o **erro médio das previsões**, permitindo saber se o modelo está funcionando bem ou precisa de ajustes.  \n",
    "\n",
    "- **Comparação entre Modelos:**  \n",
    "Se testamos diferentes algoritmos (XGBoost, LightGBM, etc.), podemos comparar os erros e escolher o melhor.  \n",
    "\n",
    "- **Ajuste de Hiperparâmetros:**  \n",
    "Usamos essas métricas para verificar **se as alterações no modelo melhoram ou pioram seu desempenho**.  \n",
    "\n",
    "**Evitar Problemas como Overfitting e Underfitting**  \n",
    "- Se o erro for **muito alto**, o modelo pode não ter aprendido o suficiente (**underfitting**).  \n",
    "- Se o erro no treino for muito menor do que no teste, o modelo pode estar **decorando os dados** (**overfitting**).  \n",
    "\n",
    "**Tomada de Decisão**  \n",
    "Se o erro médio é de **$100.000**, sabemos que o modelo pode estar **subestimando ou superestimando os preços** e podemos considerar ajustes.  \n",
    "\n",
    "**Conclusão:** MAE e RMSE são essenciais para avaliar e aprimorar modelos de Machine Learning, garantindo que suas previsões sejam mais confiáveis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço médio das casas: $499,859.71\n"
     ]
    }
   ],
   "source": [
    "preco_medio = dados[\"price\"].mean()\n",
    "print(f'Preço médio das casas: ${preco_medio:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o algoritmo prever o preço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos fazer com que o algoritmo preva o preço das casas, e faremos isso com os dois modelos diferentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço previsto para o novo imóvel: $960,084.12\n"
     ]
    }
   ],
   "source": [
    "# Criando um dicionário com os dados de um novo imóvel\n",
    "novo_imovel = {\n",
    "    'city': 'Seattle', \n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2,\n",
    "    'floors': 1,\n",
    "    'waterfront': 0,\n",
    "    'view': 2,\n",
    "    'condition': 4,\n",
    "    'idade_casa': 20,\n",
    "    'area_interna': 150,\n",
    "    'area_terreno': 300,\n",
    "    'area_acima_solo': 120,\n",
    "    'area_porao': 30,\n",
    "    'idade_apos_renovacao': 25\n",
    "}\n",
    "\n",
    "# Convertendo a cidade para o valor numérico usando LabelEncoder\n",
    "novo_imovel['city'] = label_encoder.transform([novo_imovel['city']])[0]\n",
    "\n",
    "# Convertendo para um DataFrame\n",
    "novo_imovel_df = pd.DataFrame([novo_imovel])\n",
    "\n",
    "# Fazer a previsão com o modelo treinado\n",
    "previsao = modelo_xgb.predict(novo_imovel_df)\n",
    "\n",
    "print(f'Preço previsto para o novo imóvel: ${previsao[0]:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo XGboost, preveu que uma casa, com aqueles dados que inserimos vale $960,084.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço previsto para o novo imóvel: $957,879.85\n"
     ]
    }
   ],
   "source": [
    "# Criando um dicionário com os dados de um novo imóvel\n",
    "novo_imovel = {\n",
    "    'city': 'Seattle', \n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2,\n",
    "    'floors': 1,\n",
    "    'waterfront': 0,\n",
    "    'view': 2,\n",
    "    'condition': 4,\n",
    "    'idade_casa': 20,\n",
    "    'area_interna': 150,\n",
    "    'area_terreno': 300,\n",
    "    'area_acima_solo': 120,\n",
    "    'area_porao': 30,\n",
    "    'idade_apos_renovacao': 25\n",
    "}\n",
    "\n",
    "# Convertendo a cidade para o valor numérico usando LabelEncoder\n",
    "novo_imovel['city'] = label_encoder.transform([novo_imovel['city']])[0]\n",
    "\n",
    "# Convertendo para um DataFrame\n",
    "novo_imovel_df = pd.DataFrame([novo_imovel])\n",
    "\n",
    "# Fazer a previsão com o modelo treinado\n",
    "previsao = modelo_lgb.predict(novo_imovel_df)\n",
    "\n",
    "print(f'Preço previsto para o novo imóvel: ${previsao[0]:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os mesmos dados o modelo LightGBM previu que a casa é avaliada em $957,879.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos Modelos\n",
    "\n",
    "### Resultados:\n",
    "\n",
    "#### XGBoost:\n",
    "- **MAE:** $103,800 → 20,8% do preço médio  \n",
    "- **RMSE:** $164,945 → 32,9% do preço médio  \n",
    "\n",
    "#### LightGBM:\n",
    "- **MAE:** $105,277 → 21,0% do preço médio  \n",
    "- **RMSE:** $164,486 → 32,9% do preço médio  \n",
    "\n",
    "\n",
    "\n",
    "### O que isso significa?\n",
    "- O **erro médio absoluto (MAE)** indica que, em média, o modelo erra o preço da casa em cerca de **$103K a $105K**.  \n",
    "- O **RMSE** sugere que os erros maiores (**outliers**) podem estar impactando o modelo, pois o valor está acima de **30% do preço médio**.  \n",
    "- Como o erro representa cerca de **20-21% do preço médio**, o modelo já tem um desempenho razoável, mas pode melhorar.  \n",
    "\n",
    "\n",
    "\n",
    "### Possíveis Melhorias:\n",
    "1️**Feature Engineering:** Criar novas variáveis, como **densidade populacional da cidade** ou **preço médio por metro quadrado**.  \n",
    "2️ **Tratar Outliers:** Como o **RMSE é bem maior que o MAE**, pode haver **outliers influenciando o modelo**. Podemos testar a remoção de valores extremos no preço.  \n",
    "3️ **Ajuste de Hiperparâmetros:** Testar **GridSearchCV** ou **Optuna** para encontrar os melhores parâmetros para XGBoost e LightGBM.  \n",
    "4️ **Modelos Ensemble:** Criar um modelo que **combine XGBoost e LightGBM** para aproveitar o melhor de ambos.  \n",
    "\n",
    "**Conclusão:** O modelo já apresenta um bom desempenho, mas ainda há espaço para melhorias!  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
